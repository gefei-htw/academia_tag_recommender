{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "This notebook discusses Multi-label classification methods for the [academia.stackexchange.com](https://academia.stackexchange.com/) data dump.\n",
    "\n",
    "Multilabel classification can be divided into three categories: problem transformation, algorithm adaption and ensembles. The here presented classifiers are used with the data preprocessed using [BoW](4.1-me-classification-bow.ipynb), [Word2Vec](4.2-me-classification-word2vec.ipynb), [Doc2Vec](4.2-me-classification-doc2vec.ipynb), [Fasttext](4.3-me-classification-fasttext.ipynb).\n",
    "\n",
    "## Table of Contents\n",
    "* [Problem Transformation](#problem_transformation)\n",
    "* [Algorithm Adaption](#algorithm_adaption)\n",
    "* [Ensembles](#ensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='problem_transformation'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Transformation\n",
    "\n",
    "Problem transformation methods divide the multi label classification into n binary classification tasks (n = |Label|).\n",
    "\n",
    "**DecisionTreeClassifier**\n",
    "\n",
    "~~**ExtraTreesClassifier**~~\n",
    "\n",
    "**KNeighborsClassifier**\n",
    "\n",
    "~~**RadiusNeighborsClassifier**~~\n",
    "\n",
    "**MLPClassifier**\n",
    "\n",
    "**Multioutput Classifier**\n",
    "MultiouputClassifier transforms sklearn classifier into classifiers capable of Binary Relevence.\n",
    "\n",
    "**Classifier Chain**\n",
    "<cite>[Read et al., 2011][1]</cite>\n",
    "\n",
    "**LabelPowerset**\n",
    "\n",
    "**ClasswiseClassifier**\n",
    "\n",
    "[1]: https://doi.org/10.1007/s10994-011-5256-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multioutput'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Adaption\n",
    "\n",
    "Classifiers in the category of algorithm adaption where specifically designed for multi-label classification tasks. They are usually adaptions of classifiers used for binary classification.\n",
    "\n",
    "**MLkNN**\n",
    "\n",
    "> Firstly, for each test instance, its k nearest neighbors in the training set are identified. Then, according to statistical information gained from the label sets of these neighboring instances, i.e. the number of neighboring instances belonging to each possible class, maximum a posteriori (MAP) principle is utilized to determine the label set for the test instance.\n",
    "<cite>[Zhang & Zhou, 2007][1]</cite>\n",
    "\n",
    "~~**BRkNN**~~\n",
    "\n",
    "~~> BRkNN is an adaptation of the kNN algorithm for multilabel classification that is conceptually equivalent to using the popular Binary Relevance problem transformation method in conjunction with the kNN algorithm, but |L| times faster. [L = labels]\n",
    "<cite>[Spyromitros et al., 2008][2]</cite>~~\n",
    "\n",
    "~~*BRkNNa*~~\n",
    "\n",
    "~~>  This version of the classifier assigns the labels that are assigned to at least half of the neighbors.\n",
    "<cite>[skmultilearn][3]</cite>~~\n",
    "\n",
    "~~*BRkNNb*~~\n",
    "\n",
    "~~>  This version of the classifier assigns the most popular m labels of the neighbors, where m is the average number of labels assigned to the object’s neighbors.\n",
    "<cite>[skmultilearn][4]</cite>~~\n",
    "\n",
    "**MLARAM**\n",
    "\n",
    "> an extension of fuzzy Adaptive Resonance Associative Map (ARAM) – an Adaptive Resonance Theory (ART)based neural network. It aims at speeding up the classification process in the presence of very large data.\n",
    "<cite>[F. Benites & E. Sapozhnikova, 2015][5]</cite>\n",
    "\n",
    "[1]: https://doi.org/10.1016/j.patcog.2006.12.019\n",
    "[2]: https://doi.org/10.1007/978-3-540-87881-0_40\n",
    "[3]: http://scikit.ml/api/skmultilearn.adapt.brknn.html#skmultilearn.adapt.BRkNNaClassifier\n",
    "[4]: http://scikit.ml/api/skmultilearn.adapt.brknn.html#skmultilearn.adapt.BRkNNbClassifier\n",
    "[5]: https://doi.org/10.1109/ICDMW.2015.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=ensembles/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles\n",
    "\n",
    "Classifier ensembles usually train a bunch of classifiers that decide together which labels should be applied to a sample.\n",
    "\n",
    "~~**ExtraTreesClassifier**~~\n",
    "\n",
    "~~**RandomForestClassifier**~~\n",
    "\n",
    "**RAkEL**\n",
    "\n",
    "> Rakel: randomly breaking the initial set of labels into a number of small-sized labelsets, and employing [Label powerset] to train a corresponding multilabel classifier.\n",
    "<cite>[Tsoumakas et al., 2011][1]</cite>\n",
    "\n",
    "*RAkELo*\n",
    "\n",
    "> Divides the label space in to m subsets of size k, trains a Label Powerset classifier for each subset and assign a label to an instance if more than half of all classifiers (majority) from clusters that contain the label assigned the label to the instance.\n",
    "<cite>[skmultilearn][2]</cite>\n",
    "\n",
    "*RAkELd*\n",
    "\n",
    ">Divides the label space in to equal partitions of size k, trains a Label Powerset classifier per partition and predicts by summing the result of all trained classifiers.\n",
    "<cite>[skmultilearn][3]</cite>\n",
    "\n",
    "**MajorityVotingClassifier**\n",
    "\n",
    "**LabelSpacePartitioningClassifier**\n",
    "\n",
    "<cite>[Szymański et al., 2016][4]</cite>\n",
    "\n",
    "\n",
    "\n",
    "[1]: https://doi.org/10.1109/TKDE.2010.164\n",
    "[2]: http://scikit.ml/api/skmultilearn.ensemble.rakelo.html#skmultilearn.ensemble.RakelO\n",
    "[3]: http://scikit.ml/api/skmultilearn.ensemble.rakeld.html#skmultilearn.ensemble.RakelD\n",
    "[4]: https://doi.org/10.3390/e18080282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
