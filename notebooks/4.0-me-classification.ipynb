{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "This notebook discusses Multi-label classification methods for the [academia.stackexchange.com](https://academia.stackexchange.com/) data dump.\n",
    "\n",
    "Multilabel classification can be divided into three categories: problem transformation, algorithm adaption and ensembles.\n",
    "\n",
    "## Table of Contents\n",
    "* [Problem Transformation](#problem_transformation)\n",
    "* [Algorithm Adaption](#algorithm_adaption)\n",
    "* [Ensembles](#ensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='problem_transformation'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Transformation\n",
    "\n",
    "Problem transformation methods divide the multi label classification into P binary classification tasks (b = |Labels|).\n",
    "\n",
    "**Multioutput Classifier**\n",
    "MultiouputClassifier transforms sklearn classifiers into classifiers capable of Binary Relevence.\n",
    "\n",
    "**DecisionTreeClassifier**\n",
    "Find logical structures inside the data and classify the label based on the resulting rule set.\n",
    "\n",
    "**KNeighborsClassifier**\n",
    "Find the k nearest neighbours and classify the label if based on the neighbours label.\n",
    "\n",
    "**MLPClassifier**\n",
    "Uses a multi-layer perceptron to decide whether the label should be assigned or not.\n",
    "\n",
    "**LinearSVC**\n",
    "Builds a hyperplane in the feature space that seperates positive and negative samples. Assigns label based on the location inside the feature space.\n",
    "\n",
    "**LogisticRegression**\n",
    "Calculates the probrability for that the samples belongs to the label.\n",
    "\n",
    "**Classifier Chain**\n",
    "<cite>[Read et al., 2011][1]</cite>\n",
    "Connects the binary classifiers by using the results of the previous binary classifiers.\n",
    "\n",
    "**LabelPowerset**\n",
    "<cite>[Read et al., 2011][1]</cite>\n",
    "Uses a binary classifier for each set of labels occuring the data set.\n",
    "\n",
    "**ClasswiseClassifier**\n",
    "This is a self written classifier, that improves the binary relevence by adding grid search and undersampling.\n",
    "\n",
    "[1]: https://doi.org/10.1007/s10994-011-5256-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multioutput'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Adaption\n",
    "\n",
    "Classifiers in the category of algorithm adaption where specifically designed for multi-label classification tasks. They are usually adaptions of classifiers used for binary classification.\n",
    "\n",
    "**MLkNN**\n",
    "\n",
    "> Firstly, for each test instance, its k nearest neighbors in the training set are identified. Then, according to statistical information gained from the label sets of these neighboring instances, i.e. the number of neighboring instances belonging to each possible class, maximum a posteriori (MAP) principle is utilized to determine the label set for the test instance.\n",
    "<cite>[Zhang & Zhou, 2007][1]</cite>\n",
    "\n",
    "**MLARAM**\n",
    "\n",
    "> an extension of fuzzy Adaptive Resonance Associative Map (ARAM) â€“ an Adaptive Resonance Theory (ART)based neural network. It aims at speeding up the classification process in the presence of very large data.\n",
    "<cite>[F. Benites & E. Sapozhnikova, 2015][2]</cite>\n",
    "\n",
    "[1]: https://doi.org/10.1016/j.patcog.2006.12.019\n",
    "[2]: https://doi.org/10.1109/ICDMW.2015.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=ensembles/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles\n",
    "\n",
    "Classifier ensembles usually train a bunch of classifiers that decide together which labels should be applied to a sample.\n",
    "\n",
    "**RAkEL**\n",
    "> Rakel: randomly breaking the initial set of labels into a number of small-sized labelsets, and employing [Label powerset] to train a corresponding multilabel classifier.\n",
    "<cite>[Tsoumakas et al., 2011][1]</cite>\n",
    "\n",
    "*RAkELo*\n",
    "> Divides the label space in to m subsets of size k, trains a Label Powerset classifier for each subset and assign a label to an instance if more than half of all classifiers (majority) from clusters that contain the label assigned the label to the instance.\n",
    "<cite>[skmultilearn][2]</cite>\n",
    "\n",
    "*RAkELd*\n",
    ">Divides the label space in to equal partitions of size k, trains a Label Powerset classifier per partition and predicts by summing the result of all trained classifiers.\n",
    "<cite>[skmultilearn][3]</cite>\n",
    "\n",
    "**MajorityVotingClassifier**\n",
    "Uses a couple of multi-label classifiers and decides on the classfication by majority voting.\n",
    "\n",
    "\n",
    "[1]: https://doi.org/10.1109/TKDE.2010.164\n",
    "[2]: http://scikit.ml/api/skmultilearn.ensemble.rakelo.html#skmultilearn.ensemble.RakelO\n",
    "[3]: http://scikit.ml/api/skmultilearn.ensemble.rakeld.html#skmultilearn.ensemble.RakelD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
